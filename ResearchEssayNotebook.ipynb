{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('pydsEnv': conda)"
  },
  "interpreter": {
   "hash": "cd92519e450c25804136c2008eef24c3d70be2e96d599be5f96d22ea88f45fe2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Carlos Garcia - 21000475"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### K-Folds Cross Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**K-fold.** Es una técnica de validación cruzada, cuyo objetivo es reducir el \"bias\" que puede presentarse al momento de entrenar un modelo de machine learning. Esta técnica se basa en el principio de evaluar el modelo sobre data que no ha sido utilizada para su entrenamiento, particionando el set de datos de entrenamiento para que este pueda ser usado para entrenamientos y validaciones. Su característica principal se basa en poder generar **K** particiones de la data, en las cuales cada una de estas particiones es utilizada para evaluar el modelo.\n",
    "De esta forma se entrenan sobre las K-1 y se evalua sobre la partición restante, repitiendo este proceso hasta recorrer todas las particiones generadas, los resultados obtenidos son promediados generado un estimador con menos sesgo para las métricas de evaluación a considerar.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<img src='./imgs/kfolds.png'>\n",
    "\n",
    "https://towardsdatascience.com/cross-validation-k-fold-vs-monte-carlo-e54df2fc179\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "En el proyecto de predicción de sobrevivientes del Titanic se trabajó con un split que genero sets de entrenamiento, validación y pruebas. K-folds puede ser implementado si en lugar de generar el dataset de validación inicial, se trabaja con una función que permita particionar el dataset de entrenamiento K veces, de forma que se pueda generar predicciones sobre cada una de estas particiones y promediar los resultados. Siendo estos promedios los que guardaríasmo en la bitácora del proyecto y que usaríamos para seleccionar los mejores modelos de cada tipo. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Support Vector Machines (SVM)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "- hipótesis de SVM\n",
    "- función de costo\n",
    "- Algoritmo de aprendizaje/entrenamiento\n",
    "- Propiedades, similitudes, diferencias ,ventajas y desventajas sobre otros algoritmos y modelos.\n",
    "- Kernel-trick/basis functions\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}